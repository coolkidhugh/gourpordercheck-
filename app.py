import pandas as pd
import streamlit as st
import re
import unicodedata

st.set_page_config(page_title="å¤šç»´å®¡æ ¸æ¯”å¯¹å¹³å°", layout="wide")

# --- Session State Initialization ---
# ä½¿ç”¨å­—å…¸ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ä¼šè¯çŠ¶æ€å˜é‡ï¼Œç¡®ä¿åº”ç”¨é‡å¯åçŠ¶æ€ä¸ä¸¢å¤±ï¼Œå¹¶é¿å…KeyErrorã€‚
SESSION_DEFAULTS = {
    'df1': None, 'df2': None, 'df1_name': "", 'df2_name': "",
    'ran_comparison': False, 'common_rows': pd.DataFrame(),
    'matched_df': pd.DataFrame(), 'in_file1_only': pd.DataFrame(),
    'in_file2_only': pd.DataFrame(), 'compare_cols_keys': []
}
for key, value in SESSION_DEFAULTS.items():
    if key not in st.session_state:
        st.session_state[key] = value

# --- Helper Functions ---

def forensic_clean_text(text):
    """
    å¯¹ä»»ä½•æ–‡æœ¬å­—ç¬¦ä¸²è¿›è¡Œâ€œæ³•è¯çº§â€æ·±åº¦æ¸…æ´ã€‚
    è¿™æ˜¯æˆ‘ä»¬å¯¹æŠ—â€œå¹½çµå­—ç¬¦â€ã€å…¨/åŠè§’ä¸ç»Ÿä¸€ç­‰é—®é¢˜çš„ç»ˆææ­¦å™¨ã€‚
    """
    if not isinstance(text, str): return text
    try:
        # NFKCèŒƒå¼ç»Ÿä¸€åŒ–ï¼Œå¯ä»¥å°†å…¨è§’å­—ç¬¦ï¼ˆå¦‚ï¼šï¼¡ï¼Œï¼‘ï¼‰è½¬æ¢ä¸ºåŠè§’ï¼ˆå¦‚ï¼šA, 1ï¼‰ã€‚
        cleaned_text = unicodedata.normalize('NFKC', text)
    except (TypeError, ValueError):
        return text
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤å„ç§ä¸å¯è§çš„æ§åˆ¶å­—ç¬¦ï¼ŒåŒ…æ‹¬é›¶å®½åº¦ç©ºæ ¼å’Œéä¸­æ–­ç©ºæ ¼(\xa0)ã€‚
    cleaned_text = re.sub(r'[\u200B-\u200D\uFEFF\s\xa0]+', '', cleaned_text)
    return cleaned_text.strip()

def process_and_standardize(df, mapping, case_insensitive=False, room_type_equivalents=None):
    """
    æ ¸å¿ƒæ•°æ®å¤„ç†å¼•æ“ã€‚
    æ¥æ”¶åŸå§‹DataFrameå’Œç”¨æˆ·çš„åˆ—æ˜ å°„ï¼Œè¾“å‡ºä¸€ä¸ªå¹²å‡€ã€æ ‡å‡†åŒ–çš„DataFrameç”¨äºæ¯”å¯¹ã€‚
    """
    # å¦‚æœç”¨æˆ·æ²¡æœ‰é€‰æ‹©æœ€å…³é”®çš„â€œå§“åâ€åˆ—ï¼Œåˆ™æ— æ³•è¿›è¡Œå¤„ç†ã€‚
    if not mapping.get('name'):
        return pd.DataFrame()

    standard_df = pd.DataFrame()
    
    # æ ¹æ®ç”¨æˆ·çš„é€‰æ‹©ï¼Œä»åŸå§‹DataFrameä¸­æå–éœ€è¦æ¯”å¯¹çš„åˆ—ã€‚
    for col_key, col_name in mapping.items():
        if col_name and col_name in df.columns:
            standard_df[col_key] = df[col_name]

    # --- æ™ºèƒ½æ—¥æœŸç»Ÿä¸€å¼•æ“ ---
    def robust_date_parser(series):
        """
        ä¸€ä¸ªæ›´å¼ºå¤§çš„æ—¥æœŸè§£æå™¨ï¼Œä¸“é—¨å¤„ç†ç¼ºå°‘å¹´ä»½çš„æ—¥æœŸæ ¼å¼ (å¦‚ '09/26' æˆ– '09/26 18:00')ã€‚
        """
        def process_date(date_str):
            if pd.isna(date_str): return pd.NaT # è¿”å›pandasçš„â€œéæ—¶é—´â€å¯¹è±¡
            date_str = str(date_str).strip()
            # æ£€æŸ¥æ˜¯å¦ä¸º 'æœˆ/æ—¥' æˆ– 'æœˆ/æ—¥ æ—¶:åˆ†' æ ¼å¼
            if re.match(r'^\d{1,2}/\d{1,2}', date_str):
                # åªå–æ—¥æœŸéƒ¨åˆ†ï¼ˆå¿½ç•¥æ—¶é—´ï¼‰
                date_part = date_str.split(' ')[0]
                # å‡è®¾å¹´ä»½ä¸º2025å¹´ï¼Œå¹¶é‡æ–°ç»„åˆæˆæ ‡å‡†æ ¼å¼
                return f"2025-{date_part.replace('/', '-')}"
            # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œç›´æ¥è¿”å›è®©pandaså¤„ç†
            return date_str
        
        # åº”ç”¨è‡ªå®šä¹‰å¤„ç†å‡½æ•°ï¼Œç„¶åäº¤ç»™pandasè¿›è¡Œæœ€ç»ˆè½¬æ¢
        return pd.to_datetime(series.apply(process_date), errors='coerce').dt.strftime('%Y-%m-%d')

    if 'start_date' in standard_df.columns:
        standard_df['start_date'] = robust_date_parser(standard_df['start_date'])
    if 'end_date' in standard_df.columns:
        standard_df['end_date'] = robust_date_parser(standard_df['end_date'])
    
    if 'room_type' in standard_df.columns:
        standard_df['room_type'] = standard_df['room_type'].astype(str).apply(forensic_clean_text)
        if room_type_equivalents:
            # æ¸…æ´—æˆ¿å‹æ˜ å°„å­—å…¸ï¼Œç¡®ä¿æ˜ å°„çš„keyå’Œvalueä¹Ÿæ˜¯å¹²å‡€çš„ã€‚
            cleaned_equivalents = {forensic_clean_text(k): [forensic_clean_text(val) for val in v] for k, v in room_type_equivalents.items()}
            reverse_map = {val: key for key, values in cleaned_equivalents.items() for val in values}
            standard_df['room_type'] = standard_df['room_type'].replace(reverse_map)
    
    if 'price' in standard_df.columns:
        standard_df['price'] = pd.to_numeric(standard_df['price'].astype(str).str.strip(), errors='coerce')

    # å¯¹å§“ååˆ—è¿›è¡Œæœ€ç»ˆçš„ã€æœ€å…³é”®çš„å¤„ç†ï¼šåˆ†å‰²å¤šäººå•å…ƒæ ¼ï¼ˆä¾‹å¦‚ "å¼ ä¸‰/æå››"ï¼‰ã€‚
    standard_df['name'] = standard_df['name'].astype(str).str.split(r'[ã€,ï¼Œ/]')
    standard_df = standard_df.explode('name')
    standard_df['name'] = standard_df['name'].apply(forensic_clean_text)
        
    if case_insensitive:
        standard_df['name'] = standard_df['name'].str.lower()
        
    # ç§»é™¤æ¸…æ´—åäº§ç”Ÿçš„æ— æ•ˆè¡Œï¼ˆä¾‹å¦‚å§“åå˜æˆç©ºå­—ç¬¦ä¸²ï¼‰ã€‚
    standard_df = standard_df[standard_df['name'] != ''].dropna(subset=['name']).reset_index(drop=True)
    return standard_df

def highlight_diff(row, col1, col2):
    """ä¸€ä¸ªç”¨äºDataFrameæ ·å¼åŒ–çš„å‡½æ•°ï¼Œå¦‚æœä¸¤ä¸ªæŒ‡å®šåˆ—çš„å€¼ä¸åŒï¼Œåˆ™é«˜äº®æ•´è¡Œã€‚"""
    style = 'background-color: #FFC7CE' # æµ…çº¢è‰²
    # å¢åŠ å¯¹NaNï¼ˆç©ºå€¼ï¼‰çš„åˆ¤æ–­ï¼Œé¿å…å°†ä¸¤ä¸ªç©ºå€¼ä¹Ÿåˆ¤å®šä¸ºâ€œä¸åŒâ€ã€‚
    if row.get(col1) != row.get(col2) and not (pd.isna(row.get(col1)) and pd.isna(row.get(col2))):
        return [style] * len(row)
    return [''] * len(row)

# --- UI Layout ---

st.title("å¤šç»´å®¡æ ¸æ¯”å¯¹å¹³å° V23.2 ğŸ† (ç»ˆææ™ºèƒ½æ—¥æœŸç‰ˆ)")
st.info("å…¨æ–°æ¨¡å¼ï¼šç»“æœä»¥ç‹¬ç«‹çš„æ ‡ç­¾é¡µå±•ç¤ºï¼Œå¹¶å†…ç½®æ™ºèƒ½æ—¥æœŸç»Ÿä¸€å¼•æ“ï¼Œæ¯”å¯¹æ›´ç²¾å‡†ï¼")

st.header("ç¬¬ 1 æ­¥: ä¸Šä¼ æ–‡ä»¶")
if st.button("ğŸ”„ æ¸…ç©ºå¹¶é‡ç½®"):
    st.session_state.clear()
    st.rerun()

col1, col2 = st.columns(2)
# æ–‡ä»¶ä¸Šä¼ æ§ä»¶
with col1:
    uploaded_file1 = st.file_uploader("ä¸Šä¼ åå•æ–‡ä»¶ 1", type=['csv', 'xlsx'])
    if uploaded_file1:
        st.session_state.df1 = pd.read_excel(uploaded_file1) if uploaded_file1.name.endswith('xlsx') else pd.read_csv(uploaded_file1)
        st.session_state.df1_name = uploaded_file1.name
with col2:
    uploaded_file2 = st.file_uploader("ä¸Šä¼ åå•æ–‡ä»¶ 2", type=['csv', 'xlsx'])
    if uploaded_file2:
        st.session_state.df2 = pd.read_excel(uploaded_file2) if uploaded_file2.name.endswith('xlsx') else pd.read_csv(uploaded_file2)
        st.session_state.df2_name = uploaded_file2.name

# åªæœ‰å½“ä¸¤ä¸ªæ–‡ä»¶éƒ½æˆåŠŸä¸Šä¼ åï¼Œæ‰æ˜¾ç¤ºåç»­çš„ä¸»åº”ç”¨ç•Œé¢ã€‚
if st.session_state.df1 is not None and st.session_state.df2 is not None:
    st.header("ç¬¬ 2 æ­¥: é€‰æ‹©è¦æ¯”å¯¹çš„åˆ— (å§“åå¿…é€‰)")
    mapping = {'file1': {}, 'file2': {}}
    cols_to_map = ['name', 'start_date', 'end_date', 'room_type', 'price']
    col_names_zh = ['å§“å', 'å…¥ä½æ—¥æœŸ', 'ç¦»å¼€æ—¥æœŸ', 'æˆ¿å‹', 'æˆ¿ä»·']

    cols1, cols2 = st.columns(2)
    with cols1:
        st.subheader(f"æ–‡ä»¶ 1: {st.session_state.df1_name}")
        df1_cols = [None] + list(st.session_state.df1.columns)
        for key, name_zh in zip(cols_to_map, col_names_zh):
            mapping['file1'][key] = st.selectbox(f"{name_zh}", df1_cols, key=f'f1_{key}')
    with cols2:
        st.subheader(f"æ–‡ä»¶ 2: {st.session_state.df2_name}")
        df2_cols = [None] + list(st.session_state.df2.columns)
        for key, name_zh in zip(cols_to_map, col_names_zh):
            mapping['file2'][key] = st.selectbox(f"{name_zh}", df2_cols, key=f'f2_{key}')

    st.header("ç¬¬ 3 æ­¥: é…ç½®ä¸æ‰§è¡Œ")
    room_type_equivalents = {}
    # åªæœ‰å½“ç”¨æˆ·ä¸ºä¸¤ä¸ªæ–‡ä»¶éƒ½é€‰æ‹©äº†â€œæˆ¿å‹â€åˆ—æ—¶ï¼Œæ‰æ˜¾ç¤ºæ­¤é«˜çº§åŠŸèƒ½ã€‚
    if mapping['file1'].get('room_type') and mapping['file2'].get('room_type'):
        with st.expander("â­ é«˜çº§åŠŸèƒ½ï¼šç»Ÿä¸€ä¸åŒåç§°çš„æˆ¿å‹ (ä¾‹å¦‚ï¼šè®©'å¤§åºŠæˆ¿'='King Room')"):
            unique_rooms1 = st.session_state.df1[mapping['file1']['room_type']].dropna().astype(str).unique()
            unique_rooms2 = list(st.session_state.df2[mapping['file2']['room_type']].dropna().astype(str).unique())
            for room1 in unique_rooms1:
                room_type_equivalents[room1] = st.multiselect(f"æ–‡ä»¶1çš„â€œ{room1}â€ç­‰åŒäº:", unique_rooms2, key=f"map_{room1}")

    case_insensitive = st.checkbox("æ¯”å¯¹å§“åæ—¶å¿½ç•¥å¤§å°å†™/å…¨åŠè§’", True)
    
    if st.button("ğŸš€ å¼€å§‹æ¯”å¯¹", type="primary"):
        # å¯¹ç”¨æˆ·çš„é€‰æ‹©è¿›è¡Œæœ€ç»ˆæ ¡éªŒã€‚
        if not mapping['file1'].get('name') or not mapping['file2'].get('name'):
            st.error("è¯·ç¡®ä¿ä¸¤è¾¹æ–‡ä»¶çš„â€œå§“åâ€éƒ½å·²æ­£ç¡®é€‰æ‹©ã€‚")
        else:
            with st.spinner('æ­£åœ¨æ‰§è¡Œç»ˆææ¯”å¯¹...'):
                st.session_state.ran_comparison = True
                
                # ä¸ºæ•°æ®æºé¢„è§ˆåŒºè¿›è¡ŒA-Zæ’åº
                st.session_state.df1.sort_values(by=mapping['file1']['name'], inplace=True, ignore_index=True)
                st.session_state.df2.sort_values(by=mapping['file2']['name'], inplace=True, ignore_index=True)

                # è°ƒç”¨æ ¸å¿ƒå¼•æ“å¤„ç†æ•°æ®
                std_df1 = process_and_standardize(st.session_state.df1, mapping['file1'], case_insensitive, room_type_equivalents)
                std_df2 = process_and_standardize(st.session_state.df2, mapping['file2'], case_insensitive)
                
                # ä½¿ç”¨å¤–è¿æ¥ï¼ˆouter mergeï¼‰åˆå¹¶ä¸¤ä¸ªè¡¨ï¼Œæ‰¾å‡ºæ‰€æœ‰å…³ç³»ã€‚
                merged_df = pd.merge(std_df1, std_df2, on='name', how='outer', suffixes=('_1', '_2'))
                
                # æ‰¾å‡ºä¸¤ä¸ªæ–‡ä»¶ä¸­éƒ½å­˜åœ¨çš„äººå‘˜
                cols1_for_check = [f"{c}_1" for c in std_df1.columns if c != 'name']
                cols2_for_check = [f"{c}_2" for c in std_df2.columns if c != 'name']
                both_exist_mask = merged_df[cols1_for_check].notna().any(axis=1) & merged_df[cols2_for_check].notna().any(axis=1)
                st.session_state.common_rows = merged_df[both_exist_mask].copy().reset_index(drop=True)

                # æ‰¾å‡ºä»…å•è¾¹å­˜åœ¨çš„äººå‘˜
                only_in_1_mask = merged_df[cols1_for_check].notna().any(axis=1) & merged_df[cols2_for_check].isna().all(axis=1)
                st.session_state.in_file1_only = merged_df[only_in_1_mask].reset_index(drop=True)
                
                only_in_2_mask = merged_df[cols1_for_check].isna().all(axis=1) & merged_df[cols2_for_check].notna().any(axis=1)
                st.session_state.in_file2_only = merged_df[only_in_2_mask].reset_index(drop=True)
                
                # åŠ¨æ€å†³å®šéœ€è¦æ¯”å¯¹å“ªäº›ç»†èŠ‚åˆ—
                st.session_state.compare_cols_keys = [key for key in ['start_date', 'end_date', 'room_type', 'price'] if mapping['file1'].get(key) and mapping['file2'].get(key)]
                
                # æ‰¾å‡ºä¿¡æ¯å®Œå…¨ä¸€è‡´çš„äººå‘˜
                if not st.session_state.common_rows.empty and st.session_state.compare_cols_keys:
                    condition = pd.Series(True, index=st.session_state.common_rows.index)
                    for key in st.session_state.compare_cols_keys:
                        # ä¸¤ä¸ªåˆ—çš„å€¼ç›¸ç­‰ï¼Œæˆ–è€…ä¸¤ä¸ªåˆ—éƒ½ä¸ºç©ºå€¼ï¼Œéƒ½ç®—ä½œâ€œä¸€è‡´â€ã€‚
                        condition &= (st.session_state.common_rows[f'{key}_1'] == st.session_state.common_rows[f'{key}_2']) | \
                                     (st.session_state.common_rows[f'{key}_1'].isna() & st.session_state.common_rows[f'{key}_2'].isna())
                    st.session_state.matched_df = st.session_state.common_rows[condition]
                else:
                    # å¦‚æœæ²¡æœ‰é€‰æ‹©ä»»ä½•ç»†èŠ‚åˆ—è¿›è¡Œæ¯”å¯¹ï¼Œé‚£ä¹ˆæ‰€æœ‰å…±åŒå­˜åœ¨çš„äººéƒ½ç®—ä½œâ€œä¿¡æ¯ä¸€è‡´â€ã€‚
                    st.session_state.matched_df = st.session_state.common_rows

    # --- Results Display Section ---
    # åªæœ‰å½“ç”¨æˆ·ç‚¹å‡»è¿‡â€œå¼€å§‹æ¯”å¯¹â€åï¼Œæ‰æ˜¾ç¤ºæ­¤ç»“æœåŒºåŸŸã€‚
    if st.session_state.ran_comparison:
        st.header("ç¬¬ 4 æ­¥: æŸ¥çœ‹æ¯”å¯¹ç»“æœ")

        tab_list = ["ğŸ“Š ç»“æœæ€»è§ˆ"]
        tab_name_map = {'start_date': "ğŸ•µï¸ å…¥ä½æ—¥æœŸ", 'end_date': "ğŸ•µï¸ ç¦»å¼€æ—¥æœŸ", 'room_type': "ğŸ•µï¸ æˆ¿å‹", 'price': "ğŸ•µï¸ æˆ¿ä»·"}
        
        # åŠ¨æ€ç”Ÿæˆæ ‡ç­¾é¡µçš„æ ‡é¢˜åˆ—è¡¨
        for key in st.session_state.compare_cols_keys:
            tab_list.append(tab_name_map[key])
        
        tabs = st.tabs(tab_list)

        with tabs[0]: # æ€»è§ˆæ ‡ç­¾é¡µ
            st.subheader("å®è§‚ç»Ÿè®¡")
            stat_cols = st.columns(3)
            matched_count = len(st.session_state.matched_df)
            only_1_count = len(st.session_state.in_file1_only)
            only_2_count = len(st.session_state.in_file2_only)
            stat_cols[0].metric("âœ… ä¿¡æ¯å®Œå…¨ä¸€è‡´", matched_count)
            stat_cols[1].metric(f"â“ ä»… '{st.session_state.df1_name}' æœ‰", only_1_count)
            stat_cols[2].metric(f"â“ ä»… '{st.session_state.df2_name}' æœ‰", only_2_count)

            st.subheader("äººå‘˜åå•è¯¦æƒ…")
            with st.expander(f"âœ… æŸ¥çœ‹ {matched_count} æ¡ä¿¡æ¯å®Œå…¨ä¸€è‡´çš„åå•"):
                if not st.session_state.matched_df.empty:
                    st.dataframe(st.session_state.matched_df[['name']].rename(columns={'name': 'å§“å'}))
                else:
                    st.write("æ²¡æœ‰ä¿¡æ¯å®Œå…¨ä¸€è‡´çš„äººå‘˜ã€‚")

            with st.expander(f"â“ æŸ¥çœ‹ {only_1_count} æ¡ä»…å­˜åœ¨äº '{st.session_state.df1_name}' çš„åå•"):
                if not st.session_state.in_file1_only.empty:
                    # å‡çº§ï¼šæ˜¾ç¤ºå•è¾¹äººå‘˜çš„å®Œæ•´ä¿¡æ¯ï¼Œè€Œä¸ä»…ä»…æ˜¯å§“åã€‚
                    display_cols_1 = [c for c in cols_to_map if f"{c}_1" in st.session_state.in_file1_only.columns]
                    display_df_1 = st.session_state.in_file1_only[[f"{c}_1" for c in display_cols_1]]
                    display_df_1.columns = [col_names_zh[cols_to_map.index(c)] for c in display_cols_1]
                    st.dataframe(display_df_1)
                else:
                    st.write("æ²¡æœ‰äººå‘˜ã€‚")

            with st.expander(f"â“ æŸ¥çœ‹ {only_2_count} æ¡ä»…å­˜åœ¨äº '{st.session_state.df2_name}' çš„åå•"):
                if not st.session_state.in_file2_only.empty:
                    # å‡çº§ï¼šæ˜¾ç¤ºå•è¾¹äººå‘˜çš„å®Œæ•´ä¿¡æ¯ã€‚
                    display_cols_2 = [c for c in cols_to_map if f"{c}_2" in st.session_state.in_file2_only.columns]
                    display_df_2 = st.session_state.in_file2_only[[f"{c}_2" for c in display_cols_2]]
                    display_df_2.columns = [col_names_zh[cols_to_map.index(c)] for c in display_cols_2]
                    st.dataframe(display_df_2)
                else:
                    st.write("æ²¡æœ‰äººå‘˜ã€‚")

        # åŠ¨æ€ä¸ºæ¯ä¸ªé€‰æ‹©çš„æ¯”å¯¹ç»´åº¦åˆ›å»ºä¸€ä¸ªä¸“å±çš„æ ‡ç­¾é¡µã€‚
        for i, key in enumerate(st.session_state.compare_cols_keys):
            with tabs[i+1]:
                col1_name, col2_name = f'{key}_1', f'{key}_2'
                display_name = col_names_zh[cols_to_map.index(key)]
                
                st.subheader(f"ã€{display_name}ã€‘æ¯”å¯¹è¯¦æƒ…")
                
                if not st.session_state.common_rows.empty:
                    # å‡†å¤‡ç”¨äºå½“å‰æ ‡ç­¾é¡µå±•ç¤ºçš„æ•°æ®ã€‚
                    compare_df = st.session_state.common_rows[['name', col1_name, col2_name]].copy()
                    compare_df.rename(columns={'name': 'å§“å', col1_name: f'æ–‡ä»¶1 - {display_name}', col2_name: f'æ–‡ä»¶2 - {display_name}'}, inplace=True)
                    
                    # å¯¹å­˜åœ¨å·®å¼‚çš„è¡Œè¿›è¡Œæ•´è¡Œé«˜äº®ã€‚
                    styled_df = compare_df.style.apply(highlight_diff, col1=f'æ–‡ä»¶1 - {display_name}', col2=f'æ–‡ä»¶2 - {display_name}', axis=1)
                    st.dataframe(styled_df)
                else:
                    st.info("ä¸¤ä¸ªæ–‡ä»¶ä¸­æ²¡æœ‰å…±åŒçš„äººå‘˜å¯ä¾›è¿›è¡Œç»†èŠ‚æ¯”å¯¹ã€‚")

    # --- Data Preview Section ---
    st.divider()
    st.header("åŸå§‹æ•°æ®é¢„è§ˆ (ç‚¹å‡»æ¯”å¯¹åä¼šæŒ‰å§“åæ’åº)")
    c1, c2 = st.columns(2)
    with c1:
        st.caption(f"æ–‡ä»¶ 1: {st.session_state.df1_name}")
        st.dataframe(st.session_state.df1)
    with c2:
        st.caption(f"æ–‡ä»¶ 2: {st.session_state.df2_name}")
        st.dataframe(st.session_state.df2)

